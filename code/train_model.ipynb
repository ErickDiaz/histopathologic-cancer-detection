{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/train/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tansformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"../data/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['img_path'] = train_path + train_labels[['id']] + '.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/train/f38a6374c348f90b587e046aac607995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n",
       "      <td>1</td>\n",
       "      <td>../data/train/c18f2d887b7ae4f6742ee445113fa1ae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/train/755db6279dae599ebb4d39a9123cce43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/train/bc3f0c64fb968ff4a8bd33af6971ecae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/train/068aba587a4950175d04c680d38943fd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label  \\\n",
       "0  f38a6374c348f90b587e046aac6079959adf3835      0   \n",
       "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1   \n",
       "2  755db6279dae599ebb4d39a9123cce439965282d      0   \n",
       "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0   \n",
       "4  068aba587a4950175d04c680d38943fd488d6a9d      0   \n",
       "\n",
       "                                            img_path  \n",
       "0  ../data/train/f38a6374c348f90b587e046aac607995...  \n",
       "1  ../data/train/c18f2d887b7ae4f6742ee445113fa1ae...  \n",
       "2  ../data/train/755db6279dae599ebb4d39a9123cce43...  \n",
       "3  ../data/train/bc3f0c64fb968ff4a8bd33af6971ecae...  \n",
       "4  ../data/train/068aba587a4950175d04c680d38943fd...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images = train_labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, validation_index = train_test_split(train_labels.index, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176020,)\n",
      "(44005,)\n"
     ]
    }
   ],
   "source": [
    "print(train_index.shape)\n",
    "print(validation_index.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(data.Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = self.dataset['label'][index]\n",
    "        \n",
    "        img_raw = imread(self.dataset['img_path'][index])\n",
    "        img = self.transform(img_raw)\n",
    "        \n",
    "        return [img, label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataGenerator(train_labels, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_data, batch_size=32,\n",
    "                              sampler= data.SubsetRandomSampler(train_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = data.DataLoader(train_data, batch_size=32,\n",
    "                              sampler= data.SubsetRandomSampler(validation_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet34(pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Fully connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=512, out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erick/anaconda3/envs/histopathologic_cancer/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5.. Batch 10.. Train loss: 0.889.. Train acc: 0.578.. Train avg precision: 0.393.. Train avg recall: 0.478.. \n",
      "Epoch 1/5.. Batch 20.. Train loss: 0.723.. Train acc: 0.650.. Train avg precision: 0.503.. Train avg recall: 0.587.. \n",
      "Epoch 1/5.. Batch 30.. Train loss: 0.654.. Train acc: 0.685.. Train avg precision: 0.592.. Train avg recall: 0.570.. \n",
      "Epoch 1/5.. Batch 40.. Train loss: 0.632.. Train acc: 0.694.. Train avg precision: 0.605.. Train avg recall: 0.612.. \n",
      "Epoch 1/5.. Batch 50.. Train loss: 0.621.. Train acc: 0.692.. Train avg precision: 0.610.. Train avg recall: 0.618.. \n",
      "Epoch 1/5.. Batch 60.. Train loss: 0.595.. Train acc: 0.710.. Train avg precision: 0.648.. Train avg recall: 0.637.. \n",
      "Epoch 1/5.. Batch 70.. Train loss: 0.577.. Train acc: 0.726.. Train avg precision: 0.667.. Train avg recall: 0.662.. \n",
      "Epoch 1/5.. Batch 80.. Train loss: 0.571.. Train acc: 0.730.. Train avg precision: 0.675.. Train avg recall: 0.658.. \n",
      "Epoch 1/5.. Batch 90.. Train loss: 0.564.. Train acc: 0.734.. Train avg precision: 0.692.. Train avg recall: 0.647.. \n",
      "Epoch 1/5.. Batch 100.. Train loss: 0.558.. Train acc: 0.739.. Train avg precision: 0.703.. Train avg recall: 0.654.. \n",
      "Epoch 1/5.. Batch 110.. Train loss: 0.551.. Train acc: 0.742.. Train avg precision: 0.705.. Train avg recall: 0.660.. \n",
      "Epoch 1/5.. Batch 120.. Train loss: 0.545.. Train acc: 0.747.. Train avg precision: 0.716.. Train avg recall: 0.660.. \n",
      "Epoch 1/5.. Batch 130.. Train loss: 0.534.. Train acc: 0.753.. Train avg precision: 0.722.. Train avg recall: 0.665.. \n",
      "Epoch 1/5.. Batch 140.. Train loss: 0.525.. Train acc: 0.758.. Train avg precision: 0.727.. Train avg recall: 0.672.. \n",
      "Epoch 1/5.. Batch 150.. Train loss: 0.523.. Train acc: 0.760.. Train avg precision: 0.731.. Train avg recall: 0.677.. \n",
      "Epoch 1/5.. Batch 160.. Train loss: 0.519.. Train acc: 0.761.. Train avg precision: 0.733.. Train avg recall: 0.679.. \n",
      "Epoch 1/5.. Batch 170.. Train loss: 0.514.. Train acc: 0.764.. Train avg precision: 0.738.. Train avg recall: 0.680.. \n",
      "Epoch 1/5.. Batch 180.. Train loss: 0.509.. Train acc: 0.766.. Train avg precision: 0.740.. Train avg recall: 0.684.. \n",
      "Epoch 1/5.. Batch 190.. Train loss: 0.504.. Train acc: 0.770.. Train avg precision: 0.744.. Train avg recall: 0.689.. \n",
      "Epoch 1/5.. Batch 200.. Train loss: 0.498.. Train acc: 0.772.. Train avg precision: 0.746.. Train avg recall: 0.692.. \n",
      "Epoch 1/5.. Batch 210.. Train loss: 0.497.. Train acc: 0.772.. Train avg precision: 0.747.. Train avg recall: 0.691.. \n",
      "Epoch 1/5.. Batch 220.. Train loss: 0.495.. Train acc: 0.773.. Train avg precision: 0.746.. Train avg recall: 0.689.. \n",
      "Epoch 1/5.. Batch 230.. Train loss: 0.494.. Train acc: 0.773.. Train avg precision: 0.747.. Train avg recall: 0.685.. \n",
      "Epoch 1/5.. Batch 240.. Train loss: 0.493.. Train acc: 0.773.. Train avg precision: 0.748.. Train avg recall: 0.684.. \n",
      "Epoch 1/5.. Batch 250.. Train loss: 0.493.. Train acc: 0.773.. Train avg precision: 0.748.. Train avg recall: 0.688.. \n",
      "Epoch 1/5.. Batch 260.. Train loss: 0.491.. Train acc: 0.775.. Train avg precision: 0.753.. Train avg recall: 0.689.. \n",
      "Epoch 1/5.. Batch 270.. Train loss: 0.492.. Train acc: 0.775.. Train avg precision: 0.753.. Train avg recall: 0.689.. \n",
      "Epoch 1/5.. Batch 280.. Train loss: 0.489.. Train acc: 0.777.. Train avg precision: 0.755.. Train avg recall: 0.692.. \n",
      "Epoch 1/5.. Batch 290.. Train loss: 0.488.. Train acc: 0.778.. Train avg precision: 0.755.. Train avg recall: 0.693.. \n",
      "Epoch 1/5.. Batch 300.. Train loss: 0.487.. Train acc: 0.778.. Train avg precision: 0.756.. Train avg recall: 0.692.. \n",
      "Epoch 1/5.. Batch 310.. Train loss: 0.485.. Train acc: 0.779.. Train avg precision: 0.759.. Train avg recall: 0.693.. \n",
      "Epoch 1/5.. Batch 320.. Train loss: 0.481.. Train acc: 0.782.. Train avg precision: 0.761.. Train avg recall: 0.696.. \n",
      "Epoch 1/5.. Batch 330.. Train loss: 0.480.. Train acc: 0.782.. Train avg precision: 0.761.. Train avg recall: 0.695.. \n",
      "Epoch 1/5.. Batch 340.. Train loss: 0.479.. Train acc: 0.781.. Train avg precision: 0.759.. Train avg recall: 0.699.. \n",
      "Epoch 1/5.. Batch 350.. Train loss: 0.479.. Train acc: 0.781.. Train avg precision: 0.762.. Train avg recall: 0.698.. \n",
      "Epoch 1/5.. Batch 360.. Train loss: 0.477.. Train acc: 0.782.. Train avg precision: 0.763.. Train avg recall: 0.698.. \n",
      "Epoch 1/5.. Batch 370.. Train loss: 0.476.. Train acc: 0.784.. Train avg precision: 0.765.. Train avg recall: 0.699.. \n",
      "Epoch 1/5.. Batch 380.. Train loss: 0.475.. Train acc: 0.784.. Train avg precision: 0.765.. Train avg recall: 0.700.. \n",
      "Epoch 1/5.. Batch 390.. Train loss: 0.474.. Train acc: 0.785.. Train avg precision: 0.765.. Train avg recall: 0.701.. \n",
      "Epoch 1/5.. Batch 400.. Train loss: 0.474.. Train acc: 0.785.. Train avg precision: 0.766.. Train avg recall: 0.700.. \n",
      "Epoch 1/5.. Batch 410.. Train loss: 0.474.. Train acc: 0.785.. Train avg precision: 0.766.. Train avg recall: 0.701.. \n",
      "Epoch 1/5.. Batch 420.. Train loss: 0.473.. Train acc: 0.785.. Train avg precision: 0.765.. Train avg recall: 0.702.. \n",
      "Epoch 1/5.. Batch 430.. Train loss: 0.472.. Train acc: 0.785.. Train avg precision: 0.765.. Train avg recall: 0.702.. \n",
      "Epoch 1/5.. Batch 440.. Train loss: 0.470.. Train acc: 0.786.. Train avg precision: 0.765.. Train avg recall: 0.705.. \n",
      "Epoch 1/5.. Batch 450.. Train loss: 0.468.. Train acc: 0.787.. Train avg precision: 0.766.. Train avg recall: 0.706.. \n",
      "Epoch 1/5.. Batch 460.. Train loss: 0.467.. Train acc: 0.788.. Train avg precision: 0.768.. Train avg recall: 0.705.. \n",
      "Epoch 1/5.. Batch 470.. Train loss: 0.465.. Train acc: 0.788.. Train avg precision: 0.769.. Train avg recall: 0.706.. \n",
      "Epoch 1/5.. Batch 480.. Train loss: 0.465.. Train acc: 0.789.. Train avg precision: 0.769.. Train avg recall: 0.708.. \n",
      "Epoch 1/5.. Batch 490.. Train loss: 0.464.. Train acc: 0.790.. Train avg precision: 0.769.. Train avg recall: 0.710.. \n",
      "Epoch 1/5.. Batch 500.. Train loss: 0.462.. Train acc: 0.791.. Train avg precision: 0.770.. Train avg recall: 0.711.. \n",
      "Epoch 1/5.. Batch 510.. Train loss: 0.461.. Train acc: 0.791.. Train avg precision: 0.771.. Train avg recall: 0.712.. \n",
      "Epoch 1/5.. Batch 520.. Train loss: 0.460.. Train acc: 0.792.. Train avg precision: 0.772.. Train avg recall: 0.713.. \n",
      "Epoch 1/5.. Batch 530.. Train loss: 0.459.. Train acc: 0.793.. Train avg precision: 0.772.. Train avg recall: 0.713.. \n",
      "Epoch 1/5.. Batch 540.. Train loss: 0.458.. Train acc: 0.793.. Train avg precision: 0.774.. Train avg recall: 0.714.. \n",
      "Epoch 1/5.. Batch 550.. Train loss: 0.458.. Train acc: 0.793.. Train avg precision: 0.773.. Train avg recall: 0.715.. \n",
      "Epoch 1/5.. Batch 560.. Train loss: 0.457.. Train acc: 0.793.. Train avg precision: 0.773.. Train avg recall: 0.716.. \n",
      "Epoch 1/5.. Batch 570.. Train loss: 0.457.. Train acc: 0.794.. Train avg precision: 0.774.. Train avg recall: 0.717.. \n",
      "Epoch 1/5.. Batch 580.. Train loss: 0.456.. Train acc: 0.795.. Train avg precision: 0.774.. Train avg recall: 0.719.. \n",
      "Epoch 1/5.. Batch 590.. Train loss: 0.455.. Train acc: 0.795.. Train avg precision: 0.774.. Train avg recall: 0.718.. \n",
      "Epoch 1/5.. Batch 600.. Train loss: 0.455.. Train acc: 0.795.. Train avg precision: 0.775.. Train avg recall: 0.719.. \n",
      "Epoch 1/5.. Batch 610.. Train loss: 0.454.. Train acc: 0.796.. Train avg precision: 0.775.. Train avg recall: 0.720.. \n",
      "Epoch 1/5.. Batch 620.. Train loss: 0.453.. Train acc: 0.796.. Train avg precision: 0.775.. Train avg recall: 0.721.. \n",
      "Epoch 1/5.. Batch 630.. Train loss: 0.453.. Train acc: 0.796.. Train avg precision: 0.775.. Train avg recall: 0.722.. \n",
      "Epoch 1/5.. Batch 640.. Train loss: 0.452.. Train acc: 0.796.. Train avg precision: 0.775.. Train avg recall: 0.723.. \n",
      "Epoch 1/5.. Batch 650.. Train loss: 0.451.. Train acc: 0.797.. Train avg precision: 0.776.. Train avg recall: 0.723.. \n",
      "Epoch 1/5.. Batch 660.. Train loss: 0.450.. Train acc: 0.798.. Train avg precision: 0.776.. Train avg recall: 0.725.. \n",
      "Epoch 1/5.. Batch 670.. Train loss: 0.449.. Train acc: 0.798.. Train avg precision: 0.777.. Train avg recall: 0.726.. \n",
      "Epoch 1/5.. Batch 680.. Train loss: 0.449.. Train acc: 0.798.. Train avg precision: 0.776.. Train avg recall: 0.726.. \n",
      "Epoch 1/5.. Batch 690.. Train loss: 0.448.. Train acc: 0.799.. Train avg precision: 0.778.. Train avg recall: 0.727.. \n",
      "Epoch 1/5.. Batch 700.. Train loss: 0.448.. Train acc: 0.799.. Train avg precision: 0.777.. Train avg recall: 0.728.. \n",
      "Epoch 1/5.. Batch 710.. Train loss: 0.447.. Train acc: 0.800.. Train avg precision: 0.778.. Train avg recall: 0.729.. \n",
      "Epoch 1/5.. Batch 720.. Train loss: 0.446.. Train acc: 0.800.. Train avg precision: 0.779.. Train avg recall: 0.730.. \n",
      "Epoch 1/5.. Batch 730.. Train loss: 0.445.. Train acc: 0.801.. Train avg precision: 0.779.. Train avg recall: 0.730.. \n",
      "Epoch 1/5.. Batch 740.. Train loss: 0.444.. Train acc: 0.802.. Train avg precision: 0.780.. Train avg recall: 0.730.. \n",
      "Epoch 1/5.. Batch 750.. Train loss: 0.444.. Train acc: 0.802.. Train avg precision: 0.781.. Train avg recall: 0.730.. \n",
      "Epoch 1/5.. Batch 760.. Train loss: 0.444.. Train acc: 0.802.. Train avg precision: 0.781.. Train avg recall: 0.731.. \n",
      "Epoch 1/5.. Batch 770.. Train loss: 0.444.. Train acc: 0.801.. Train avg precision: 0.780.. Train avg recall: 0.731.. \n",
      "Epoch 1/5.. Batch 780.. Train loss: 0.442.. Train acc: 0.802.. Train avg precision: 0.781.. Train avg recall: 0.732.. \n",
      "Epoch 1/5.. Batch 790.. Train loss: 0.442.. Train acc: 0.802.. Train avg precision: 0.781.. Train avg recall: 0.732.. \n",
      "Epoch 1/5.. Batch 800.. Train loss: 0.442.. Train acc: 0.802.. Train avg precision: 0.781.. Train avg recall: 0.731.. \n",
      "Epoch 1/5.. Batch 810.. Train loss: 0.442.. Train acc: 0.802.. Train avg precision: 0.781.. Train avg recall: 0.730.. \n",
      "Epoch 1/5.. Batch 820.. Train loss: 0.441.. Train acc: 0.802.. Train avg precision: 0.781.. Train avg recall: 0.731.. \n",
      "Epoch 1/5.. Batch 830.. Train loss: 0.440.. Train acc: 0.802.. Train avg precision: 0.781.. Train avg recall: 0.732.. \n",
      "Epoch 1/5.. Batch 840.. Train loss: 0.440.. Train acc: 0.803.. Train avg precision: 0.782.. Train avg recall: 0.732.. \n",
      "Epoch 1/5.. Batch 850.. Train loss: 0.440.. Train acc: 0.803.. Train avg precision: 0.781.. Train avg recall: 0.733.. \n",
      "Epoch 1/5.. Batch 860.. Train loss: 0.439.. Train acc: 0.803.. Train avg precision: 0.782.. Train avg recall: 0.733.. \n",
      "Epoch 1/5.. Batch 870.. Train loss: 0.438.. Train acc: 0.804.. Train avg precision: 0.783.. Train avg recall: 0.734.. \n",
      "Epoch 1/5.. Batch 880.. Train loss: 0.437.. Train acc: 0.804.. Train avg precision: 0.782.. Train avg recall: 0.734.. \n",
      "Epoch 1/5.. Batch 890.. Train loss: 0.437.. Train acc: 0.804.. Train avg precision: 0.783.. Train avg recall: 0.734.. \n",
      "Epoch 1/5.. Batch 900.. Train loss: 0.437.. Train acc: 0.804.. Train avg precision: 0.783.. Train avg recall: 0.735.. \n",
      "Epoch 1/5.. Batch 910.. Train loss: 0.436.. Train acc: 0.804.. Train avg precision: 0.783.. Train avg recall: 0.736.. \n",
      "Epoch 1/5.. Batch 920.. Train loss: 0.436.. Train acc: 0.804.. Train avg precision: 0.782.. Train avg recall: 0.736.. \n",
      "Epoch 1/5.. Batch 930.. Train loss: 0.435.. Train acc: 0.804.. Train avg precision: 0.782.. Train avg recall: 0.736.. \n",
      "Epoch 1/5.. Batch 940.. Train loss: 0.435.. Train acc: 0.804.. Train avg precision: 0.784.. Train avg recall: 0.736.. \n",
      "Epoch 1/5.. Batch 950.. Train loss: 0.434.. Train acc: 0.804.. Train avg precision: 0.784.. Train avg recall: 0.737.. \n",
      "Epoch 1/5.. Batch 960.. Train loss: 0.434.. Train acc: 0.805.. Train avg precision: 0.784.. Train avg recall: 0.738.. \n",
      "Epoch 1/5.. Batch 970.. Train loss: 0.434.. Train acc: 0.805.. Train avg precision: 0.784.. Train avg recall: 0.738.. \n",
      "Epoch 1/5.. Batch 980.. Train loss: 0.434.. Train acc: 0.805.. Train avg precision: 0.784.. Train avg recall: 0.738.. \n",
      "Epoch 1/5.. Batch 990.. Train loss: 0.433.. Train acc: 0.805.. Train avg precision: 0.784.. Train avg recall: 0.738.. \n",
      "Epoch 1/5.. Batch 1000.. Train loss: 0.433.. Train acc: 0.805.. Train avg precision: 0.785.. Train avg recall: 0.738.. \n",
      "Epoch 1/5.. Batch 1010.. Train loss: 0.433.. Train acc: 0.805.. Train avg precision: 0.785.. Train avg recall: 0.739.. \n",
      "Epoch 1/5.. Batch 1020.. Train loss: 0.432.. Train acc: 0.806.. Train avg precision: 0.785.. Train avg recall: 0.739.. \n",
      "Epoch 1/5.. Batch 1030.. Train loss: 0.432.. Train acc: 0.806.. Train avg precision: 0.786.. Train avg recall: 0.739.. \n",
      "Epoch 1/5.. Batch 1040.. Train loss: 0.431.. Train acc: 0.806.. Train avg precision: 0.785.. Train avg recall: 0.740.. \n",
      "Epoch 1/5.. Batch 1050.. Train loss: 0.431.. Train acc: 0.806.. Train avg precision: 0.786.. Train avg recall: 0.740.. \n",
      "Epoch 1/5.. Batch 1060.. Train loss: 0.431.. Train acc: 0.806.. Train avg precision: 0.786.. Train avg recall: 0.739.. \n",
      "Epoch 1/5.. Batch 1070.. Train loss: 0.430.. Train acc: 0.806.. Train avg precision: 0.786.. Train avg recall: 0.739.. \n",
      "Epoch 1/5.. Batch 1080.. Train loss: 0.430.. Train acc: 0.806.. Train avg precision: 0.787.. Train avg recall: 0.738.. \n",
      "Epoch 1/5.. Batch 1090.. Train loss: 0.430.. Train acc: 0.806.. Train avg precision: 0.786.. Train avg recall: 0.739.. \n",
      "Epoch 1/5.. Batch 1100.. Train loss: 0.430.. Train acc: 0.806.. Train avg precision: 0.786.. Train avg recall: 0.740.. \n",
      "Epoch 1/5.. Batch 1110.. Train loss: 0.430.. Train acc: 0.806.. Train avg precision: 0.786.. Train avg recall: 0.740.. \n",
      "Epoch 1/5.. Batch 1120.. Train loss: 0.429.. Train acc: 0.806.. Train avg precision: 0.787.. Train avg recall: 0.740.. \n",
      "Epoch 1/5.. Batch 1130.. Train loss: 0.429.. Train acc: 0.806.. Train avg precision: 0.787.. Train avg recall: 0.739.. \n",
      "Epoch 1/5.. Batch 1140.. Train loss: 0.429.. Train acc: 0.806.. Train avg precision: 0.787.. Train avg recall: 0.739.. \n",
      "Epoch 1/5.. Batch 1150.. Train loss: 0.429.. Train acc: 0.806.. Train avg precision: 0.787.. Train avg recall: 0.739.. \n",
      "Epoch 1/5.. Batch 1160.. Train loss: 0.428.. Train acc: 0.807.. Train avg precision: 0.788.. Train avg recall: 0.740.. \n",
      "Epoch 1/5.. Batch 1170.. Train loss: 0.428.. Train acc: 0.807.. Train avg precision: 0.788.. Train avg recall: 0.740.. \n",
      "Epoch 1/5.. Batch 1180.. Train loss: 0.427.. Train acc: 0.807.. Train avg precision: 0.788.. Train avg recall: 0.740.. \n",
      "Epoch 1/5.. Batch 1190.. Train loss: 0.427.. Train acc: 0.808.. Train avg precision: 0.789.. Train avg recall: 0.740.. \n",
      "Epoch 1/5.. Batch 1200.. Train loss: 0.427.. Train acc: 0.808.. Train avg precision: 0.789.. Train avg recall: 0.741.. \n",
      "Epoch 1/5.. Batch 1210.. Train loss: 0.426.. Train acc: 0.808.. Train avg precision: 0.790.. Train avg recall: 0.741.. \n",
      "Epoch 1/5.. Batch 1220.. Train loss: 0.426.. Train acc: 0.808.. Train avg precision: 0.789.. Train avg recall: 0.741.. \n",
      "Epoch 1/5.. Batch 1230.. Train loss: 0.426.. Train acc: 0.808.. Train avg precision: 0.790.. Train avg recall: 0.741.. \n",
      "Epoch 1/5.. Batch 1240.. Train loss: 0.425.. Train acc: 0.809.. Train avg precision: 0.790.. Train avg recall: 0.741.. \n",
      "Epoch 1/5.. Batch 1250.. Train loss: 0.425.. Train acc: 0.808.. Train avg precision: 0.790.. Train avg recall: 0.742.. \n",
      "Epoch 1/5.. Batch 1260.. Train loss: 0.425.. Train acc: 0.809.. Train avg precision: 0.791.. Train avg recall: 0.741.. \n",
      "Epoch 1/5.. Batch 1270.. Train loss: 0.425.. Train acc: 0.809.. Train avg precision: 0.790.. Train avg recall: 0.742.. \n",
      "Epoch 1/5.. Batch 1280.. Train loss: 0.424.. Train acc: 0.809.. Train avg precision: 0.791.. Train avg recall: 0.742.. \n",
      "Epoch 1/5.. Batch 1290.. Train loss: 0.424.. Train acc: 0.809.. Train avg precision: 0.791.. Train avg recall: 0.743.. \n",
      "Epoch 1/5.. Batch 1300.. Train loss: 0.423.. Train acc: 0.809.. Train avg precision: 0.791.. Train avg recall: 0.743.. \n",
      "Epoch 1/5.. Batch 1310.. Train loss: 0.423.. Train acc: 0.810.. Train avg precision: 0.791.. Train avg recall: 0.743.. \n",
      "Epoch 1/5.. Batch 1320.. Train loss: 0.423.. Train acc: 0.810.. Train avg precision: 0.791.. Train avg recall: 0.743.. \n",
      "Epoch 1/5.. Batch 1330.. Train loss: 0.422.. Train acc: 0.810.. Train avg precision: 0.791.. Train avg recall: 0.743.. \n",
      "Epoch 1/5.. Batch 1340.. Train loss: 0.422.. Train acc: 0.810.. Train avg precision: 0.792.. Train avg recall: 0.744.. \n",
      "Epoch 1/5.. Batch 1350.. Train loss: 0.422.. Train acc: 0.810.. Train avg precision: 0.791.. Train avg recall: 0.744.. \n",
      "Epoch 1/5.. Batch 1360.. Train loss: 0.422.. Train acc: 0.810.. Train avg precision: 0.791.. Train avg recall: 0.744.. \n",
      "Epoch 1/5.. Batch 1370.. Train loss: 0.421.. Train acc: 0.810.. Train avg precision: 0.791.. Train avg recall: 0.744.. \n",
      "Epoch 1/5.. Batch 1380.. Train loss: 0.421.. Train acc: 0.810.. Train avg precision: 0.791.. Train avg recall: 0.745.. \n",
      "Epoch 1/5.. Batch 1390.. Train loss: 0.421.. Train acc: 0.811.. Train avg precision: 0.792.. Train avg recall: 0.744.. \n",
      "Epoch 1/5.. Batch 1400.. Train loss: 0.420.. Train acc: 0.811.. Train avg precision: 0.792.. Train avg recall: 0.745.. \n",
      "Epoch 1/5.. Batch 1410.. Train loss: 0.420.. Train acc: 0.811.. Train avg precision: 0.792.. Train avg recall: 0.745.. \n",
      "Epoch 1/5.. Batch 1420.. Train loss: 0.420.. Train acc: 0.811.. Train avg precision: 0.792.. Train avg recall: 0.745.. \n",
      "Epoch 1/5.. Batch 1430.. Train loss: 0.420.. Train acc: 0.811.. Train avg precision: 0.792.. Train avg recall: 0.745.. \n",
      "Epoch 1/5.. Batch 1440.. Train loss: 0.420.. Train acc: 0.811.. Train avg precision: 0.792.. Train avg recall: 0.745.. \n",
      "Epoch 1/5.. Batch 1450.. Train loss: 0.420.. Train acc: 0.811.. Train avg precision: 0.792.. Train avg recall: 0.745.. \n",
      "Epoch 1/5.. Batch 1460.. Train loss: 0.419.. Train acc: 0.811.. Train avg precision: 0.793.. Train avg recall: 0.745.. \n",
      "Epoch 1/5.. Batch 1470.. Train loss: 0.420.. Train acc: 0.811.. Train avg precision: 0.793.. Train avg recall: 0.745.. \n",
      "Epoch 1/5.. Batch 1480.. Train loss: 0.420.. Train acc: 0.811.. Train avg precision: 0.793.. Train avg recall: 0.745.. \n",
      "Epoch 1/5.. Batch 1490.. Train loss: 0.420.. Train acc: 0.811.. Train avg precision: 0.792.. Train avg recall: 0.746.. \n",
      "Epoch 1/5.. Batch 1500.. Train loss: 0.420.. Train acc: 0.811.. Train avg precision: 0.793.. Train avg recall: 0.746.. \n",
      "Epoch 1/5.. Batch 1510.. Train loss: 0.420.. Train acc: 0.811.. Train avg precision: 0.793.. Train avg recall: 0.746.. \n",
      "Epoch 1/5.. Batch 1520.. Train loss: 0.419.. Train acc: 0.812.. Train avg precision: 0.793.. Train avg recall: 0.746.. \n",
      "Epoch 1/5.. Batch 1530.. Train loss: 0.419.. Train acc: 0.812.. Train avg precision: 0.793.. Train avg recall: 0.746.. \n",
      "Epoch 1/5.. Batch 1540.. Train loss: 0.419.. Train acc: 0.812.. Train avg precision: 0.794.. Train avg recall: 0.746.. \n",
      "Epoch 1/5.. Batch 1550.. Train loss: 0.418.. Train acc: 0.812.. Train avg precision: 0.794.. Train avg recall: 0.747.. \n",
      "Epoch 1/5.. Batch 1560.. Train loss: 0.419.. Train acc: 0.812.. Train avg precision: 0.794.. Train avg recall: 0.746.. \n",
      "Epoch 1/5.. Batch 1570.. Train loss: 0.418.. Train acc: 0.812.. Train avg precision: 0.794.. Train avg recall: 0.747.. \n",
      "Epoch 1/5.. Batch 1580.. Train loss: 0.418.. Train acc: 0.812.. Train avg precision: 0.794.. Train avg recall: 0.747.. \n",
      "Epoch 1/5.. Batch 1590.. Train loss: 0.418.. Train acc: 0.812.. Train avg precision: 0.794.. Train avg recall: 0.747.. \n",
      "Epoch 1/5.. Batch 1600.. Train loss: 0.417.. Train acc: 0.812.. Train avg precision: 0.794.. Train avg recall: 0.748.. \n",
      "Epoch 1/5.. Batch 1610.. Train loss: 0.417.. Train acc: 0.813.. Train avg precision: 0.794.. Train avg recall: 0.748.. \n",
      "Epoch 1/5.. Batch 1620.. Train loss: 0.417.. Train acc: 0.813.. Train avg precision: 0.795.. Train avg recall: 0.748.. \n",
      "Epoch 1/5.. Batch 1630.. Train loss: 0.417.. Train acc: 0.813.. Train avg precision: 0.795.. Train avg recall: 0.748.. \n",
      "Epoch 1/5.. Batch 1640.. Train loss: 0.416.. Train acc: 0.813.. Train avg precision: 0.795.. Train avg recall: 0.748.. \n",
      "Epoch 1/5.. Batch 1650.. Train loss: 0.416.. Train acc: 0.813.. Train avg precision: 0.795.. Train avg recall: 0.749.. \n",
      "Epoch 1/5.. Batch 1660.. Train loss: 0.416.. Train acc: 0.813.. Train avg precision: 0.795.. Train avg recall: 0.749.. \n",
      "Epoch 1/5.. Batch 1670.. Train loss: 0.416.. Train acc: 0.813.. Train avg precision: 0.795.. Train avg recall: 0.750.. \n",
      "Epoch 1/5.. Batch 1680.. Train loss: 0.415.. Train acc: 0.814.. Train avg precision: 0.796.. Train avg recall: 0.750.. \n",
      "Epoch 1/5.. Batch 1690.. Train loss: 0.416.. Train acc: 0.814.. Train avg precision: 0.796.. Train avg recall: 0.750.. \n",
      "Epoch 1/5.. Batch 1700.. Train loss: 0.415.. Train acc: 0.814.. Train avg precision: 0.796.. Train avg recall: 0.750.. \n",
      "Epoch 1/5.. Batch 1710.. Train loss: 0.415.. Train acc: 0.814.. Train avg precision: 0.796.. Train avg recall: 0.750.. \n",
      "Epoch 1/5.. Batch 1720.. Train loss: 0.415.. Train acc: 0.814.. Train avg precision: 0.796.. Train avg recall: 0.750.. \n",
      "Epoch 1/5.. Batch 1730.. Train loss: 0.415.. Train acc: 0.814.. Train avg precision: 0.797.. Train avg recall: 0.751.. \n",
      "Epoch 1/5.. Batch 1740.. Train loss: 0.415.. Train acc: 0.814.. Train avg precision: 0.796.. Train avg recall: 0.751.. \n",
      "Epoch 1/5.. Batch 1750.. Train loss: 0.414.. Train acc: 0.815.. Train avg precision: 0.797.. Train avg recall: 0.751.. \n",
      "Epoch 1/5.. Batch 1760.. Train loss: 0.414.. Train acc: 0.815.. Train avg precision: 0.797.. Train avg recall: 0.752.. \n",
      "Epoch 1/5.. Batch 1770.. Train loss: 0.413.. Train acc: 0.815.. Train avg precision: 0.797.. Train avg recall: 0.752.. \n",
      "Epoch 1/5.. Batch 1780.. Train loss: 0.413.. Train acc: 0.815.. Train avg precision: 0.798.. Train avg recall: 0.752.. \n",
      "Epoch 1/5.. Batch 1790.. Train loss: 0.413.. Train acc: 0.815.. Train avg precision: 0.798.. Train avg recall: 0.752.. \n",
      "Epoch 1/5.. Batch 1800.. Train loss: 0.412.. Train acc: 0.815.. Train avg precision: 0.798.. Train avg recall: 0.753.. \n",
      "Epoch 1/5.. Batch 1810.. Train loss: 0.412.. Train acc: 0.815.. Train avg precision: 0.798.. Train avg recall: 0.752.. \n",
      "Epoch 1/5.. Batch 1820.. Train loss: 0.412.. Train acc: 0.816.. Train avg precision: 0.798.. Train avg recall: 0.753.. \n",
      "Epoch 1/5.. Batch 1830.. Train loss: 0.412.. Train acc: 0.816.. Train avg precision: 0.798.. Train avg recall: 0.753.. \n",
      "Epoch 1/5.. Batch 1840.. Train loss: 0.411.. Train acc: 0.816.. Train avg precision: 0.798.. Train avg recall: 0.754.. \n",
      "Epoch 1/5.. Batch 1850.. Train loss: 0.411.. Train acc: 0.816.. Train avg precision: 0.799.. Train avg recall: 0.754.. \n",
      "Epoch 1/5.. Batch 1860.. Train loss: 0.411.. Train acc: 0.816.. Train avg precision: 0.799.. Train avg recall: 0.754.. \n",
      "Epoch 1/5.. Batch 1870.. Train loss: 0.411.. Train acc: 0.816.. Train avg precision: 0.799.. Train avg recall: 0.755.. \n",
      "Epoch 1/5.. Batch 1880.. Train loss: 0.411.. Train acc: 0.817.. Train avg precision: 0.799.. Train avg recall: 0.754.. \n",
      "Epoch 1/5.. Batch 1890.. Train loss: 0.410.. Train acc: 0.817.. Train avg precision: 0.800.. Train avg recall: 0.755.. \n",
      "Epoch 1/5.. Batch 1900.. Train loss: 0.410.. Train acc: 0.817.. Train avg precision: 0.799.. Train avg recall: 0.756.. \n",
      "Epoch 1/5.. Batch 1910.. Train loss: 0.410.. Train acc: 0.817.. Train avg precision: 0.800.. Train avg recall: 0.755.. \n",
      "Epoch 1/5.. Batch 1920.. Train loss: 0.409.. Train acc: 0.817.. Train avg precision: 0.800.. Train avg recall: 0.756.. \n",
      "Epoch 1/5.. Batch 1930.. Train loss: 0.409.. Train acc: 0.817.. Train avg precision: 0.800.. Train avg recall: 0.756.. \n",
      "Epoch 1/5.. Batch 1940.. Train loss: 0.409.. Train acc: 0.817.. Train avg precision: 0.800.. Train avg recall: 0.756.. \n",
      "Epoch 1/5.. Batch 1950.. Train loss: 0.409.. Train acc: 0.818.. Train avg precision: 0.800.. Train avg recall: 0.756.. \n",
      "Epoch 1/5.. Batch 1960.. Train loss: 0.409.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.756.. \n",
      "Epoch 1/5.. Batch 1970.. Train loss: 0.408.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.756.. \n",
      "Epoch 1/5.. Batch 1980.. Train loss: 0.408.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.756.. \n",
      "Epoch 1/5.. Batch 1990.. Train loss: 0.408.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.757.. \n",
      "Epoch 1/5.. Batch 2000.. Train loss: 0.408.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.757.. \n",
      "Epoch 1/5.. Batch 2010.. Train loss: 0.408.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.757.. \n",
      "Epoch 1/5.. Batch 2020.. Train loss: 0.408.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.757.. \n",
      "Epoch 1/5.. Batch 2030.. Train loss: 0.408.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.757.. \n",
      "Epoch 1/5.. Batch 2040.. Train loss: 0.407.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.757.. \n",
      "Epoch 1/5.. Batch 2050.. Train loss: 0.407.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.757.. \n",
      "Epoch 1/5.. Batch 2060.. Train loss: 0.407.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.757.. \n",
      "Epoch 1/5.. Batch 2070.. Train loss: 0.407.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.757.. \n",
      "Epoch 1/5.. Batch 2080.. Train loss: 0.408.. Train acc: 0.819.. Train avg precision: 0.802.. Train avg recall: 0.757.. \n",
      "Epoch 1/5.. Batch 2090.. Train loss: 0.407.. Train acc: 0.819.. Train avg precision: 0.802.. Train avg recall: 0.758.. \n",
      "Epoch 1/5.. Batch 2100.. Train loss: 0.408.. Train acc: 0.818.. Train avg precision: 0.801.. Train avg recall: 0.758.. \n",
      "Epoch 1/5.. Batch 2110.. Train loss: 0.407.. Train acc: 0.819.. Train avg precision: 0.802.. Train avg recall: 0.758.. \n",
      "Epoch 1/5.. Batch 2120.. Train loss: 0.407.. Train acc: 0.819.. Train avg precision: 0.802.. Train avg recall: 0.758.. \n",
      "Epoch 1/5.. Batch 2130.. Train loss: 0.407.. Train acc: 0.819.. Train avg precision: 0.802.. Train avg recall: 0.758.. \n",
      "Epoch 1/5.. Batch 2140.. Train loss: 0.407.. Train acc: 0.819.. Train avg precision: 0.802.. Train avg recall: 0.758.. \n",
      "Epoch 1/5.. Batch 2150.. Train loss: 0.407.. Train acc: 0.819.. Train avg precision: 0.802.. Train avg recall: 0.758.. \n",
      "Epoch 1/5.. Batch 2160.. Train loss: 0.406.. Train acc: 0.819.. Train avg precision: 0.802.. Train avg recall: 0.759.. \n",
      "Epoch 1/5.. Batch 2170.. Train loss: 0.406.. Train acc: 0.819.. Train avg precision: 0.802.. Train avg recall: 0.759.. \n",
      "Epoch 1/5.. Batch 2180.. Train loss: 0.406.. Train acc: 0.819.. Train avg precision: 0.802.. Train avg recall: 0.759.. \n",
      "Epoch 1/5.. Batch 2190.. Train loss: 0.406.. Train acc: 0.820.. Train avg precision: 0.803.. Train avg recall: 0.759.. \n",
      "Epoch 1/5.. Batch 2200.. Train loss: 0.405.. Train acc: 0.820.. Train avg precision: 0.802.. Train avg recall: 0.760.. \n",
      "Epoch 1/5.. Batch 2210.. Train loss: 0.405.. Train acc: 0.820.. Train avg precision: 0.803.. Train avg recall: 0.760.. \n",
      "Epoch 1/5.. Batch 2220.. Train loss: 0.405.. Train acc: 0.820.. Train avg precision: 0.803.. Train avg recall: 0.760.. \n",
      "Epoch 1/5.. Batch 2230.. Train loss: 0.405.. Train acc: 0.820.. Train avg precision: 0.803.. Train avg recall: 0.760.. \n",
      "Epoch 1/5.. Batch 2240.. Train loss: 0.405.. Train acc: 0.820.. Train avg precision: 0.803.. Train avg recall: 0.760.. \n",
      "Epoch 1/5.. Batch 2250.. Train loss: 0.404.. Train acc: 0.820.. Train avg precision: 0.803.. Train avg recall: 0.761.. \n",
      "Epoch 1/5.. Batch 2260.. Train loss: 0.404.. Train acc: 0.820.. Train avg precision: 0.803.. Train avg recall: 0.761.. \n",
      "Epoch 1/5.. Batch 2270.. Train loss: 0.404.. Train acc: 0.821.. Train avg precision: 0.803.. Train avg recall: 0.761.. \n",
      "Epoch 1/5.. Batch 2280.. Train loss: 0.404.. Train acc: 0.821.. Train avg precision: 0.803.. Train avg recall: 0.761.. \n",
      "Epoch 1/5.. Batch 2290.. Train loss: 0.403.. Train acc: 0.821.. Train avg precision: 0.804.. Train avg recall: 0.761.. \n",
      "Epoch 1/5.. Batch 2300.. Train loss: 0.403.. Train acc: 0.821.. Train avg precision: 0.804.. Train avg recall: 0.762.. \n",
      "Epoch 1/5.. Batch 2310.. Train loss: 0.403.. Train acc: 0.821.. Train avg precision: 0.804.. Train avg recall: 0.762.. \n",
      "Epoch 1/5.. Batch 2320.. Train loss: 0.403.. Train acc: 0.821.. Train avg precision: 0.804.. Train avg recall: 0.762.. \n",
      "Epoch 1/5.. Batch 2330.. Train loss: 0.402.. Train acc: 0.821.. Train avg precision: 0.804.. Train avg recall: 0.762.. \n",
      "Epoch 1/5.. Batch 2340.. Train loss: 0.402.. Train acc: 0.821.. Train avg precision: 0.804.. Train avg recall: 0.762.. \n",
      "Epoch 1/5.. Batch 2350.. Train loss: 0.402.. Train acc: 0.821.. Train avg precision: 0.804.. Train avg recall: 0.762.. \n",
      "Epoch 1/5.. Batch 2360.. Train loss: 0.402.. Train acc: 0.821.. Train avg precision: 0.804.. Train avg recall: 0.762.. \n",
      "Epoch 1/5.. Batch 2370.. Train loss: 0.402.. Train acc: 0.821.. Train avg precision: 0.804.. Train avg recall: 0.762.. \n",
      "Epoch 1/5.. Batch 2380.. Train loss: 0.401.. Train acc: 0.822.. Train avg precision: 0.804.. Train avg recall: 0.762.. \n",
      "Epoch 1/5.. Batch 2390.. Train loss: 0.401.. Train acc: 0.822.. Train avg precision: 0.804.. Train avg recall: 0.763.. \n",
      "Epoch 1/5.. Batch 2400.. Train loss: 0.401.. Train acc: 0.822.. Train avg precision: 0.804.. Train avg recall: 0.763.. \n",
      "Epoch 1/5.. Batch 2410.. Train loss: 0.401.. Train acc: 0.822.. Train avg precision: 0.804.. Train avg recall: 0.763.. \n",
      "Epoch 1/5.. Batch 2420.. Train loss: 0.401.. Train acc: 0.822.. Train avg precision: 0.804.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2430.. Train loss: 0.400.. Train acc: 0.822.. Train avg precision: 0.805.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2440.. Train loss: 0.400.. Train acc: 0.822.. Train avg precision: 0.805.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2450.. Train loss: 0.400.. Train acc: 0.822.. Train avg precision: 0.805.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2460.. Train loss: 0.400.. Train acc: 0.823.. Train avg precision: 0.805.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2470.. Train loss: 0.400.. Train acc: 0.823.. Train avg precision: 0.805.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2480.. Train loss: 0.400.. Train acc: 0.823.. Train avg precision: 0.805.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2490.. Train loss: 0.399.. Train acc: 0.823.. Train avg precision: 0.805.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2500.. Train loss: 0.399.. Train acc: 0.823.. Train avg precision: 0.805.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2510.. Train loss: 0.399.. Train acc: 0.823.. Train avg precision: 0.805.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2520.. Train loss: 0.399.. Train acc: 0.823.. Train avg precision: 0.805.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2530.. Train loss: 0.399.. Train acc: 0.823.. Train avg precision: 0.806.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2540.. Train loss: 0.398.. Train acc: 0.823.. Train avg precision: 0.806.. Train avg recall: 0.764.. \n",
      "Epoch 1/5.. Batch 2550.. Train loss: 0.398.. Train acc: 0.824.. Train avg precision: 0.806.. Train avg recall: 0.765.. \n",
      "Epoch 1/5.. Batch 2560.. Train loss: 0.398.. Train acc: 0.824.. Train avg precision: 0.806.. Train avg recall: 0.765.. \n",
      "Epoch 1/5.. Batch 2570.. Train loss: 0.398.. Train acc: 0.824.. Train avg precision: 0.806.. Train avg recall: 0.765.. \n",
      "Epoch 1/5.. Batch 2580.. Train loss: 0.398.. Train acc: 0.824.. Train avg precision: 0.806.. Train avg recall: 0.765.. \n",
      "Epoch 1/5.. Batch 2590.. Train loss: 0.398.. Train acc: 0.824.. Train avg precision: 0.806.. Train avg recall: 0.765.. \n",
      "Epoch 1/5.. Batch 2600.. Train loss: 0.398.. Train acc: 0.824.. Train avg precision: 0.807.. Train avg recall: 0.765.. \n",
      "Epoch 1/5.. Batch 2610.. Train loss: 0.397.. Train acc: 0.824.. Train avg precision: 0.806.. Train avg recall: 0.765.. \n",
      "Epoch 1/5.. Batch 2620.. Train loss: 0.397.. Train acc: 0.824.. Train avg precision: 0.806.. Train avg recall: 0.765.. \n",
      "Epoch 1/5.. Batch 2630.. Train loss: 0.397.. Train acc: 0.824.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2640.. Train loss: 0.397.. Train acc: 0.824.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2650.. Train loss: 0.397.. Train acc: 0.824.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2660.. Train loss: 0.396.. Train acc: 0.824.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2670.. Train loss: 0.396.. Train acc: 0.824.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2680.. Train loss: 0.396.. Train acc: 0.824.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2690.. Train loss: 0.396.. Train acc: 0.824.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2700.. Train loss: 0.396.. Train acc: 0.824.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2710.. Train loss: 0.396.. Train acc: 0.824.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2720.. Train loss: 0.396.. Train acc: 0.825.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2730.. Train loss: 0.396.. Train acc: 0.825.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2740.. Train loss: 0.395.. Train acc: 0.825.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2750.. Train loss: 0.395.. Train acc: 0.825.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2760.. Train loss: 0.395.. Train acc: 0.825.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2770.. Train loss: 0.395.. Train acc: 0.825.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2780.. Train loss: 0.395.. Train acc: 0.825.. Train avg precision: 0.808.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2790.. Train loss: 0.395.. Train acc: 0.825.. Train avg precision: 0.808.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2800.. Train loss: 0.395.. Train acc: 0.825.. Train avg precision: 0.807.. Train avg recall: 0.767.. \n",
      "Epoch 1/5.. Batch 2810.. Train loss: 0.394.. Train acc: 0.825.. Train avg precision: 0.808.. Train avg recall: 0.767.. \n",
      "Epoch 1/5.. Batch 2820.. Train loss: 0.394.. Train acc: 0.825.. Train avg precision: 0.807.. Train avg recall: 0.767.. \n",
      "Epoch 1/5.. Batch 2830.. Train loss: 0.394.. Train acc: 0.825.. Train avg precision: 0.807.. Train avg recall: 0.766.. \n",
      "Epoch 1/5.. Batch 2840.. Train loss: 0.394.. Train acc: 0.825.. Train avg precision: 0.808.. Train avg recall: 0.766.. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c5cbd59a8c78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/histopathologic_cancer/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## USE GPU ##\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "print_every = 10\n",
    "\n",
    "loss_sum = 0\n",
    "correct_sum = 0\n",
    "samples = 0\n",
    "sum_precision = 0\n",
    "sum_recall = 0\n",
    "valid_count = 0\n",
    "total_train_batch = 0\n",
    "\n",
    "val_loss_sum = 0\n",
    "val_precision_sum = 0\n",
    "val_recall_sum = 0\n",
    "val_samples = 0\n",
    "total_val_batch = 0\n",
    "\n",
    "train_metrics = []\n",
    "valid_metrics = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ## Training\n",
    "    batch = 1\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        total_train_batch += 1\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        y = y.view(-1, 1).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        samples += x.shape[0]\n",
    "        loss_sum += loss.item() * x.shape[0] \n",
    "        y_pred = (output >= 0.5).float()\n",
    "        num_corrects = torch.sum(y_pred == y)\n",
    "        correct_sum += num_corrects\n",
    "  \n",
    "        precision = precision_score(y.to('cpu'), y_pred.to('cpu'))\n",
    "        recall = recall_score(y.to('cpu'), y_pred.to('cpu'))\n",
    "        sum_precision += precision\n",
    "        sum_recall += recall\n",
    "        \n",
    "        if batch % print_every == 0:\n",
    "            train_loss = float(loss_sum)/float(samples)\n",
    "            train_acc = float(correct_sum)/float(samples)\n",
    "            train_prec = float(sum_precision)/float(total_train_batch)\n",
    "            train_rec = float(sum_recall)/float(total_train_batch)\n",
    "            train_metrics.append([epoch+1, total_train_batch, train_acc, train_prec, train_rec])\n",
    "                            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Batch {batch}.. \"\n",
    "                  f\"Train loss: {train_loss:.3f}.. \"\n",
    "                  f\"Train acc: {train_acc:.3f}.. \"\n",
    "                  f\"Train avg precision: {train_prec:.3f}.. \"\n",
    "                  f\"Train avg recall: {train_rec:.3f}.. \")\n",
    "            \n",
    "        batch +=1\n",
    "    \n",
    "\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        print(\"== Validation step\")\n",
    "        for x_val, y_val in valid_loader:\n",
    "            total_val_batch +=1\n",
    "            x_val = x_val.cuda()\n",
    "            y_val = y_val.cuda()\n",
    "            y_val = y_val.view(-1, 1).float()\n",
    "\n",
    "            output_val = model(x_val)\n",
    "            loss_val = criterion(output_val, y_val)\n",
    "            y_val_pred = (output_val >= 0.5).float()\n",
    "\n",
    "            val_samples += x_val.shape[0]\n",
    "            val_loss_sum = loss_val.item() * x_val.shape[0]\n",
    "\n",
    "            val_precision = precision_score(y_val.to('cpu'), y_val_pred.to('cpu'))\n",
    "            val_recall = recall_score(y_val.to('cpu'), y_val_pred.to('cpu'))\n",
    "            val_precision_sum += val_precision\n",
    "            val_recall_sum += val_recall\n",
    "            \n",
    "            if total_val_batch % print_every == 0:\n",
    "                val = float(val_loss_sum)/float(val_samples)\n",
    "                prec = float(val_precision_sum)/float(total_val_batch)\n",
    "                rec = float(val_recall_sum)/float(total_val_batch)\n",
    "                \n",
    "                valid_metrics.append([epoch+1, total_val_batch, val, prec, rec])\n",
    "                \n",
    "                print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                      f\"Valid loss: {val:.3f}.. \"\n",
    "                      f\"Valid avg presision: {prec:.3f}.. \"\n",
    "                      f\"Valid avg recall: {rec:.3f}.. \")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
